{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'M', 'E', 'S']\n",
      "{'B': 0.6345649207515482, 'S': 0.36543507924845176}\n",
      "{'B': {'E': 0.8532242244876338, 'M': 0.14677577551236617}, 'E': {'B': 0.48537965431249463, 'S': 0.5146203456875054}, 'S': {'S': 0.42896261210773334, 'B': 0.5710373878922667}, 'M': {'M': 0.3456713007046277, 'E': 0.6543286992953723}}\n",
      "dict_keys(['B', 'E', 'S', 'M'])\n",
      "vocabulary cap:  4700\n"
     ]
    }
   ],
   "source": [
    "# load trained HMM model\n",
    "import json\n",
    "with open('./hmm-zh-segmentation.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "states = data['states']\n",
    "start_probability = data['start_probability']\n",
    "transition_probability = data['transition_probability']\n",
    "emission_probability = data['emission_probability']\n",
    "vocabulary = data['vocabulary']\n",
    "print(states)\n",
    "print(start_probability)\n",
    "print(transition_probability)\n",
    "print(emission_probability.keys())\n",
    "print('vocabulary cap: ', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B', 1: 'M', 2: 'E', 3: 'S'} {'B': 0, 'M': 1, 'E': 2, 'S': 3}\n"
     ]
    }
   ],
   "source": [
    "def generate_index_map(lables):\n",
    "    id2label = {}\n",
    "    label2id = {}\n",
    "    for idx, label in enumerate(lables):\n",
    "        id2label[idx] = label\n",
    "        label2id[label] = idx\n",
    "    return id2label, label2id\n",
    " \n",
    "states_id2label, states_label2id = generate_index_map(states)\n",
    "vocabulary_id2label, vocabulary_label2id = generate_index_map(vocabulary)\n",
    "print(states_id2label, states_label2id)\n",
    "# print(vocabulary_id2label, vocabulary_label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B', 1: 'M', 2: 'E', 3: 'S'}\n",
      "状态转移矩阵 A:  [[0.         0.14677578 0.85322422 0.        ]\n",
      " [0.         0.3456713  0.6543287  0.        ]\n",
      " [0.48537965 0.         0.         0.51462035]\n",
      " [0.57103739 0.         0.         0.42896261]]\n",
      "初始状态概率向量 π:  [0.63456492 0.         0.         0.36543508]\n",
      "观测概率矩阵 B:  [[1.70874158e-06 0.00000000e+00 4.61360227e-05 ... 0.00000000e+00\n",
      "  2.17010181e-03 2.22136405e-05]\n",
      " [0.00000000e+00 0.00000000e+00 2.28527899e-05 ... 0.00000000e+00\n",
      "  4.72290992e-04 8.37935631e-05]\n",
      " [8.54370790e-06 1.70874158e-06 3.24660900e-05 ... 0.00000000e+00\n",
      "  1.58400344e-03 1.19611911e-05]\n",
      " [0.00000000e+00 0.00000000e+00 1.71519722e-05 ... 3.81154938e-06\n",
      "  1.46744651e-04 2.85866203e-05]]\n"
     ]
    }
   ],
   "source": [
    "def convert_map_to_vector(probs_map, col_label2id):\n",
    "    \"\"\"conver to 1d vector\"\"\"\n",
    "    v = np.zeros(len(col_label2id), dtype=float)\n",
    "    for col, value in probs_map.items():\n",
    "        v[col_label2id[col]] = value\n",
    "    return v\n",
    "\n",
    "\n",
    "def convert_map_to_matrix(probs_map, row_label2id, col_label2id):\n",
    "    \"\"\"convert to matrix\"\"\"\n",
    "    m = np.zeros((len(row_label2id), len(col_label2id)), dtype=float)\n",
    "    for row, cols in probs_map.items():\n",
    "        for col, value in cols.items():\n",
    "            m[row_label2id[row]][col_label2id[col]] = value\n",
    "    return m\n",
    "\n",
    "print(states_id2label)\n",
    "A = convert_map_to_matrix(transition_probability, states_label2id, states_label2id)\n",
    "print('状态转移矩阵 A: ', A)\n",
    "pi = convert_map_to_vector(start_probability, states_label2id)\n",
    "print('初始状态概率向量 π: ', pi)\n",
    "B = convert_map_to_matrix(emission_probability, states_label2id, vocabulary_label2id)\n",
    "print('观测概率矩阵 B: ', B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs_idxs, A, B, pi):\n",
    "    \"\"\"\n",
    "    -------\n",
    "    V : numpy.ndarray\n",
    "        V [s][t] = Maximum probability of an observation sequence ending\n",
    "                   at time 't' with final state 's'\n",
    "    prev : numpy.ndarray\n",
    "        Contains a pointer to the previous state at t-1 that maximizes\n",
    "        V[state][t]\n",
    "        \n",
    "    V对应δ，prev对应ψ\n",
    "    \"\"\"\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_idxs)\n",
    "    prev = np.zeros((T - 1, N), dtype=int)\n",
    "\n",
    "    # DP matrix containing max likelihood of state at a given time\n",
    "    V = np.zeros((N, T))\n",
    "    V[:,0] = pi * B[:,obs_idxs[0]]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for n in range(N):\n",
    "            seq_probs = V[:,t-1] * A[:,n] * B[n, obs_idxs[t]]\n",
    "            prev[t-1,n] = np.argmax(seq_probs)\n",
    "            V[n,t] = np.max(seq_probs)\n",
    "\n",
    "    reversed_path = []\n",
    "    state_ptr = np.argmax(V[:,-1])  # end state\n",
    "    reversed_path.append(state_ptr)\n",
    "    for ptrs in reversed(prev):\n",
    "        state_ptr = ptrs[state_ptr]\n",
    "        reversed_path.append(state_ptr)\n",
    "    path_idx = reversed(reversed_path)\n",
    "\n",
    "    return path_idx, [states[x] for x in path_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(observations):\n",
    "    obs_seq = [vocabulary_label2id[o] for o in observations]\n",
    "    words = []\n",
    "    path_idx, path = viterbi(obs_seq, A, B, pi)\n",
    "    word = []\n",
    "    for char, state in zip(observations, path):\n",
    "        word.append(char)\n",
    "        if state in ['E', 'S']:\n",
    "            words.append(''.join(word))\n",
    "            word = []\n",
    "    if len(word) > 0:\n",
    "        words.append(''.join(word))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['小明', '是', '个', '好', '学生']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('小明是个好学生')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['清华', '大学']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('清华大学')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['干一', '行行', '一行']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('干一行行一行')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['干一行', '要行', '一行']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('干一行要行一行')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['作战', '处女', '干部']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('作战处女干部')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['作战处', '的', '女', '干部']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation('作战处的女干部')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
